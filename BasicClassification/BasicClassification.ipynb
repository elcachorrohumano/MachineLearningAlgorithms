{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# * Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment you will implement the Naive Bayes Classifier. Before starting this assignment, make sure you understand the concepts discussed in the videos in Week 2 about Naive Bayes. You can also find it useful to read Chapter 1 of the textbook.\n",
    "\n",
    "\n",
    "Also, make sure that you are familiar with the `numpy.ndarray` class of python's `numpy` library and that you are able to answer the following questions:\n",
    "\n",
    "Let's assume `a` is a numpy array.\n",
    "* What is an array's shape (e.g., what is the meaning of `a.shape`)?  \n",
    "* What is numpy's reshaping operation? How much computational over-head would it induce?  \n",
    "* What is numpy's transpose operation, and how it is different from reshaping? Does it cause computation overhead?\n",
    "* What is the meaning of the commands `a.reshape(-1, 1)` and `a.reshape(-1)`?\n",
    "* Would happens to the variable `a` after we call `b = a.reshape(-1)`? Does any of the attributes of `a` change?\n",
    "* How do assignments in python and numpy work in general?\n",
    "    * Does the `b=a` statement use copying by value? Or is it copying by reference?\n",
    "    * Would the answer to the previous question change depending on whether `a` is a numpy array or a scalar value?\n",
    "    \n",
    "You can answer all of these questions by\n",
    "\n",
    "    1. Reading numpy's documentation from https://numpy.org/doc/stable/.\n",
    "    2. Making trials using dummy variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Assignment Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The UC Irvine machine learning data repository hosts a famous dataset, the Pima Indians dataset, on whether a patient has diabetes originally owned by the National Institute of Diabetes and Digestive and Kidney Diseases and donated by Vincent Sigillito. You can find it at  https://www.kaggle.com/uciml/pima-indians-diabetes-database/data. This data has a set of attributes of patients, and a categorical variable telling whether the patient is diabetic or not. For several attributes in this data set, a value of 0 may indicate a missing value of the variable. It has a total of 768 data-points. \n",
    "\n",
    "* **Part 1-A)** First, you will build a simple naive Bayes classifier to classify this data set. We will use 20% of the data for evaluation and the other 80% for training. \n",
    "\n",
    "  You should use a normal distribution to model each of the class-conditional distributions.\n",
    "\n",
    "  Report the accuracy of the classifier on the 20% evaluation data, where accuracy is the number of correct predictions as a fraction of total predictions.\n",
    "\n",
    "* **Part 1-B)** Next, you will adjust your code so that, for attributes 3 (Diastolic blood pressure), 4 (Triceps skin fold thickness), 6 (Body mass index), and 8 (Age), it regards a value of 0 as a missing value when estimating the class-conditional distributions, and the posterior.\n",
    "\n",
    "  Report the accuracy of the classifier on the 20% that was held out for evaluation.\n",
    "\n",
    "* **Part 1-C)** Last, you will have some experience with SVMLight, an off-the-shelf implementation of Support Vector Machines or SVMs. For now, you don't need to understand much about SVM's, we will explore them in more depth in the following exercises. You will install SVMLight, which you can find at http://svmlight.joachims.org, to train and evaluate an SVM to classify this data.\n",
    "\n",
    "  You should NOT substitute NA values for zeros for attributes 3, 4, 6, and 8.\n",
    "  \n",
    "  Report the accuracy of the classifier on the held out 20%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1 Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The UC Irvine's Machine Learning Data Repository Department hosts a Kaggle Competition with famous collection of data on whether a patient has diabetes (the Pima Indians dataset), originally owned by the National Institute of Diabetes and Digestive and Kidney Diseases and donated by Vincent Sigillito. \n",
    "\n",
    "You can find this data at https://www.kaggle.com/uciml/pima-indians-diabetes-database/data. The Kaggle website offers valuable visualizations of the original data dimensions in its dashboard. It is quite insightful to take the time and make sense of the data using their dashboard before applying any method to the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2 Information Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Input/Output**: This data has a set of attributes of patients, and a categorical variable telling whether the patient is diabetic or not. \n",
    "\n",
    "* **Missing Data**: For several attributes in this data set, a value of 0 may indicate a missing value of the variable.\n",
    "\n",
    "* **Final Goal**: We want to build a classifier that can predict whether a patient has diabetes or not. To do this, we will train multiple kinds of models, and will be handing the missing data with different approaches for each method (i.e., some methods will ignore their existence, while others may do something about the missing data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.3 Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from aml_utils import test_case_checker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0              6      148             72             35        0  33.6   \n",
       "1              1       85             66             29        0  26.6   \n",
       "2              8      183             64              0        0  23.3   \n",
       "3              1       89             66             23       94  28.1   \n",
       "4              0      137             40             35      168  43.1   \n",
       "..           ...      ...            ...            ...      ...   ...   \n",
       "763           10      101             76             48      180  32.9   \n",
       "764            2      122             70             27        0  36.8   \n",
       "765            5      121             72             23      112  26.2   \n",
       "766            1      126             60              0        0  30.1   \n",
       "767            1       93             70             31        0  30.4   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                       0.627   50        1  \n",
       "1                       0.351   31        0  \n",
       "2                       0.672   32        1  \n",
       "3                       0.167   21        0  \n",
       "4                       2.288   33        1  \n",
       "..                        ...  ...      ...  \n",
       "763                     0.171   63        0  \n",
       "764                     0.340   27        0  \n",
       "765                     0.245   30        0  \n",
       "766                     0.349   47        1  \n",
       "767                     0.315   23        0  \n",
       "\n",
       "[768 rows x 9 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('diabetes.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1 Splitting The Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will shuffle the data completely, and forget about the order in the original csv file. \n",
    "\n",
    "* The training and evaluation dataframes will be named ```train_df``` and ```eval_df```, respectively.\n",
    "\n",
    "* We will also create the 2-d numpy array `train_features` whose number of rows is the number of training samples, and the number of columns is 8 (i.e., the number of features). We will define `eval_features` in a similar fashion\n",
    "\n",
    "* We would also create the 1-d numpy arrays `train_labels` and `eval_labels` which contain the training and evaluation labels, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's generate the split ourselves.\n",
    "np_random = np.random.RandomState(seed=12345)\n",
    "rand_unifs = np_random.uniform(0,1,size=df.shape[0])\n",
    "division_thresh = np.percentile(rand_unifs, 80)\n",
    "train_indicator = rand_unifs < division_thresh\n",
    "eval_indicator = rand_unifs >= division_thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>116</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.6</td>\n",
       "      <td>0.201</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>614 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0              1       85             66             29        0  26.6   \n",
       "1              8      183             64              0        0  23.3   \n",
       "2              1       89             66             23       94  28.1   \n",
       "3              0      137             40             35      168  43.1   \n",
       "4              5      116             74              0        0  25.6   \n",
       "..           ...      ...            ...            ...      ...   ...   \n",
       "609           10      101             76             48      180  32.9   \n",
       "610            2      122             70             27        0  36.8   \n",
       "611            5      121             72             23      112  26.2   \n",
       "612            1      126             60              0        0  30.1   \n",
       "613            1       93             70             31        0  30.4   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                       0.351   31        0  \n",
       "1                       0.672   32        1  \n",
       "2                       0.167   21        0  \n",
       "3                       2.288   33        1  \n",
       "4                       0.201   30        0  \n",
       "..                        ...  ...      ...  \n",
       "609                     0.171   63        0  \n",
       "610                     0.340   27        0  \n",
       "611                     0.245   30        0  \n",
       "612                     0.349   47        1  \n",
       "613                     0.315   23        0  \n",
       "\n",
       "[614 rows x 9 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = df[train_indicator].reset_index(drop=True)\n",
    "train_features = train_df.loc[:, train_df.columns != 'Outcome'].values\n",
    "train_labels = train_df['Outcome'].values\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>78</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>88</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.248</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>168</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.537</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>118</td>\n",
       "      <td>84</td>\n",
       "      <td>47</td>\n",
       "      <td>230</td>\n",
       "      <td>45.8</td>\n",
       "      <td>0.551</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>107</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29.6</td>\n",
       "      <td>0.254</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>8</td>\n",
       "      <td>65</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.600</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>2</td>\n",
       "      <td>99</td>\n",
       "      <td>60</td>\n",
       "      <td>17</td>\n",
       "      <td>160</td>\n",
       "      <td>36.6</td>\n",
       "      <td>0.453</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>0</td>\n",
       "      <td>181</td>\n",
       "      <td>88</td>\n",
       "      <td>44</td>\n",
       "      <td>510</td>\n",
       "      <td>43.3</td>\n",
       "      <td>0.222</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>0</td>\n",
       "      <td>123</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36.3</td>\n",
       "      <td>0.258</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>9</td>\n",
       "      <td>89</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22.5</td>\n",
       "      <td>0.142</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>154 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0              6      148             72             35        0  33.6   \n",
       "1              3       78             50             32       88  31.0   \n",
       "2             10      168             74              0        0  38.0   \n",
       "3              0      118             84             47      230  45.8   \n",
       "4              7      107             74              0        0  29.6   \n",
       "..           ...      ...            ...            ...      ...   ...   \n",
       "149            8       65             72             23        0  32.0   \n",
       "150            2       99             60             17      160  36.6   \n",
       "151            0      181             88             44      510  43.3   \n",
       "152            0      123             72              0        0  36.3   \n",
       "153            9       89             62              0        0  22.5   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                       0.627   50        1  \n",
       "1                       0.248   26        1  \n",
       "2                       0.537   34        1  \n",
       "3                       0.551   31        1  \n",
       "4                       0.254   31        1  \n",
       "..                        ...  ...      ...  \n",
       "149                     0.600   42        0  \n",
       "150                     0.453   21        0  \n",
       "151                     0.222   26        1  \n",
       "152                     0.258   52        1  \n",
       "153                     0.142   33        0  \n",
       "\n",
       "[154 rows x 9 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df = df[eval_indicator].reset_index(drop=True)\n",
    "eval_features = eval_df.loc[:, eval_df.columns != 'Outcome'].values\n",
    "eval_labels = eval_df['Outcome'].values\n",
    "eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainX.shape:  (614, 8)\n",
      "TrainY.shape:  (614,)\n",
      "TestX.shape:  (154, 8)\n",
      "TestY.shape:  (154,)\n"
     ]
    }
   ],
   "source": [
    "print(\"TrainX.shape: \", train_features.shape)\n",
    "print(\"TrainY.shape: \", train_labels.shape)\n",
    "print(\"TestX.shape: \", eval_features.shape)\n",
    "print(\"TestY.shape: \", eval_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2 Pre-processing The Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the columns exhibit missing values. We will use a Naive Bayes Classifier later that will treat such missing values in a special way.  To be specific, for attribute 3 (Diastolic blood pressure), attribute 4 (Triceps skin fold thickness), attribute 6 (Body mass index), and attribute 8 (Age), we should regard a value of 0 as a missing value.\n",
    "\n",
    "Therefore, we will be creating the `train_featues_with_nans` and `eval_features_with_nans` numpy arrays to be just like their `train_features` and `eval_features` counter-parts, but with the zero-values in such columns replaced with nans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_with_nans = train_df.copy(deep=True)\n",
    "eval_df_with_nans = eval_df.copy(deep=True)\n",
    "for col_with_nans in ['BloodPressure', 'SkinThickness', 'BMI', 'Age']:\n",
    "    train_df_with_nans[col_with_nans] = train_df_with_nans[col_with_nans].replace(0, np.nan)\n",
    "    eval_df_with_nans[col_with_nans] = eval_df_with_nans[col_with_nans].replace(0, np.nan)\n",
    "train_features_with_nans = train_df_with_nans.loc[:, train_df_with_nans.columns != 'Outcome'].values\n",
    "eval_features_with_nans = eval_df_with_nans.loc[:, eval_df_with_nans.columns != 'Outcome'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the training rows with at least one missing values.\n",
      "\n",
      "You can see that such incomplete data points constitute a substantial part of the data.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>116</td>\n",
       "      <td>74.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>25.6</td>\n",
       "      <td>0.201</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10</td>\n",
       "      <td>115</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>35.3</td>\n",
       "      <td>0.134</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>125</td>\n",
       "      <td>96.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.232</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>110</td>\n",
       "      <td>92.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>37.6</td>\n",
       "      <td>0.191</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>6</td>\n",
       "      <td>162</td>\n",
       "      <td>62.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>24.3</td>\n",
       "      <td>0.178</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>4</td>\n",
       "      <td>136</td>\n",
       "      <td>70.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>31.2</td>\n",
       "      <td>1.182</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>1</td>\n",
       "      <td>106</td>\n",
       "      <td>76.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>37.5</td>\n",
       "      <td>0.197</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>6</td>\n",
       "      <td>190</td>\n",
       "      <td>92.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>35.5</td>\n",
       "      <td>0.278</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>186 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "1              8      183           64.0            NaN        0  23.3   \n",
       "4              5      116           74.0            NaN        0  25.6   \n",
       "5             10      115            NaN            NaN        0  35.3   \n",
       "7              8      125           96.0            NaN        0   NaN   \n",
       "8              4      110           92.0            NaN        0  37.6   \n",
       "..           ...      ...            ...            ...      ...   ...   \n",
       "598            6      162           62.0            NaN        0  24.3   \n",
       "599            4      136           70.0            NaN        0  31.2   \n",
       "605            1      106           76.0            NaN        0  37.5   \n",
       "606            6      190           92.0            NaN        0  35.5   \n",
       "612            1      126           60.0            NaN        0  30.1   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  Outcome  \n",
       "1                       0.672   32        1  \n",
       "4                       0.201   30        0  \n",
       "5                       0.134   29        0  \n",
       "7                       0.232   54        1  \n",
       "8                       0.191   30        0  \n",
       "..                        ...  ...      ...  \n",
       "598                     0.178   50        1  \n",
       "599                     1.182   22        1  \n",
       "605                     0.197   26        0  \n",
       "606                     0.278   66        1  \n",
       "612                     0.349   47        1  \n",
       "\n",
       "[186 rows x 9 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Here are the training rows with at least one missing values.')\n",
    "print('')\n",
    "print('You can see that such incomplete data points constitute a substantial part of the data.')\n",
    "print('')\n",
    "nan_training_data = train_df_with_nans[train_df_with_nans.isna().any(axis=1)]\n",
    "nan_training_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Part 1 (Building a simple Naive Bayes Classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a single sample $(\\mathbf{x}, y)$, where the feature vector is denoted with $\\mathbf{x}$, and the label is denoted with $y$. We will also denote the $j^{th}$ feature of $\\mathbf{x}$ with $x^{(j)}$.\n",
    "\n",
    "According to the textbook, the Naive Bayes Classifier uses the following decision rule:\n",
    "\n",
    "\"Choose $y$ such that $$\\bigg[\\log p(y) + \\sum_{j} \\log p(x^{(j)}|y) \\bigg]$$ is the largest\"\n",
    "\n",
    "However, we first need to define the probabilistic models of the prior $p(y)$ and the class-conditional feature distributions $p(x^{(j)}|y)$ using the training data.\n",
    "\n",
    "* **Modelling the prior $p(y)$**: We fit a Bernoulli distribution to the `Outcome` variable of `train_df`.\n",
    "* **Modelling the class-conditional feature distributions $p(x^{(j)}|y)$**: We fit Gaussian distributions, and infer the Gaussian mean and variance parameters from `train_df`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\">Task 1</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function `log_prior` that takes a numpy array `train_labels` as input, and outputs the following vector as a column numpy array (i.e., with shape $(2,1)$).\n",
    "\n",
    "$$\\log p_y =\\begin{bmatrix}\\log p(y=0)\\\\\\log p(y=1)\\end{bmatrix}$$\n",
    "\n",
    "Try and avoid the utilization of loops as much as possible. No loops are necessary.\n",
    "\n",
    "**Hint**: Make sure all the array shapes are what you need and expect. You can reshape any numpy array without any tangible computational over-head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0b1857ce843a420e1121e5cdbcb34b78",
     "grade": false,
     "grade_id": "cell-540952d95c213032",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def log_prior(train_labels):\n",
    "    \n",
    "    # your code here\n",
    "    train_labels.reshape(-1,)\n",
    "    n = train_labels.shape[0] # cantidad de datos\n",
    "    n_true = np.sum(train_labels) # cantidad de datos verdaderos\n",
    "    n_false = n - n_true # cantidad de datos falsos\n",
    "    log_prob_y_0 = np.log(n_false/n) # logaritmo de la probabilidad de que y sea 0\n",
    "    log_prob_y_1 = np.log(n_true/n) # logaritmo de la probabilidad de que y sea 1\n",
    "    log_py = np.array([log_prob_y_0, log_prob_y_1]).reshape(2,1) # vector de logaritmos de las probabilidades\n",
    "    \n",
    "    assert log_py.shape == (2,1)\n",
    "    \n",
    "    return log_py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "62d977dd29201423aa65d4964e7a9cf3",
     "grade": false,
     "grade_id": "cell-89c12d30b6fb44cb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Performing sanity checks on your implementation\n",
    "\n",
    "some_labels = np.array([0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1])\n",
    "some_log_py = log_prior(some_labels)\n",
    "assert np.array_equal(some_log_py.round(3), np.array([[-0.916], [-0.511]]))\n",
    "\n",
    "# Checking against the pre-computed test database\n",
    "\n",
    "test_results = test_case_checker(log_prior, task_id=1)\n",
    "assert test_results['passed'], test_results['message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "code_folding": [
     19,
     40,
     51,
     63,
     116,
     267,
     280
    ],
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1d0d0ba9ed4dc246df14b14374e57327",
     "grade": true,
     "grade_id": "cell-e263f2b1878b37bc",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# The following are hints to make your life easier duing debugging if you failed the pre-computed tests.\n",
    "#\n",
    "#   When an error is raised in checking against the pre-computed test database:\n",
    "#\n",
    "#     0. test_results will be a python dictionary, with the bug information stored in it. Don't be afraid to look into it!\n",
    "#\n",
    "#     1. You can access the failed test arguments by reading test_results['test_kwargs']. test_results['test_kwargs'] will be\n",
    "#        another python dictionary with its keys being the argument names and the values being the argument values.\n",
    "#\n",
    "#     2. test_results['correct_sol'] will contain the correct solution.\n",
    "#\n",
    "#     3. test_results['stu_sol'] will contain your implementation's returned solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.41610786],\n",
       "       [-1.07766068]])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_py = log_prior(train_labels)\n",
    "log_py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\">Task 2</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function `cc_mean_ignore_missing` that takes the numpy arrays `train_features` and `train_labels` as input, and outputs the following matrix with the shape $(8,2)$, where 8 is the number of features.\n",
    "\n",
    "$$\\mu_y = \\begin{bmatrix} \\mathbb{E}[x^{(0)}|y=0] & \\mathbb{E}[x^{(0)}|y=1]\\\\\n",
    "\\mathbb{E}[x^{(1)}|y=0] & \\mathbb{E}[x^{(1)}|y=1] \\\\\n",
    "\\cdots & \\cdots\\\\\n",
    "\\mathbb{E}[x^{(7)}|y=0] & \\mathbb{E}[x^{(7)}|y=1]\\end{bmatrix}$$\n",
    "\n",
    "Some points regarding this task:\n",
    "\n",
    "* The `train_features` numpy array has a shape of `(N,8)` where `N` is the number of training data points, and 8 is the number of the features. \n",
    "\n",
    "* The `train_labels` numpy array has a shape of `(N,)`. \n",
    "\n",
    "* **You can assume that `train_features` has no missing elements in this task**.\n",
    "\n",
    "* Try and avoid the utilization of loops as much as possible. No loops are necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "143a0428d530470b279e80620b392dbc",
     "grade": false,
     "grade_id": "cell-9482e9412e53e401",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def cc_mean_ignore_missing(train_features, train_labels):\n",
    "    N, d = train_features.shape\n",
    "    \n",
    "    features_with_labels = np.column_stack((train_features, train_labels)) # matriz de caracteristicas con etiquetas\n",
    "    positive_XY = features_with_labels[features_with_labels[:, -1] == 1, :] # matriz de caracteristicas con etiquetas (positivos)\n",
    "    negative_XY = features_with_labels[features_with_labels[:, -1] == 0, :] # matriz de caracteristicas con etiquetas (negativos)\n",
    "\n",
    "    means_positive = np.mean(positive_XY[:, :-1], axis=0) # media de cada característica (positivos)\n",
    "    means_negative = np.mean(negative_XY[:, :-1], axis=0) # media de cada característica (negativos)\n",
    "\n",
    "    mu_y = np.column_stack((means_negative, means_positive)) # juntar los dos vectores\n",
    "\n",
    "    assert mu_y.shape == (d, 2)\n",
    "    return mu_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8a050487bbbbe6aafb16a2edbf05a35c",
     "grade": false,
     "grade_id": "cell-feae5e6e77107267",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Performing sanity checks on your implementation\n",
    "\n",
    "some_feats = np.array([[  1. ,  85. ,  66. ,  29. ,   0. ,  26.6,   0.4,  31. ],\n",
    "                       [  8. , 183. ,  64. ,   0. ,   0. ,  23.3,   0.7,  32. ],\n",
    "                       [  1. ,  89. ,  66. ,  23. ,  94. ,  28.1,   0.2,  21. ],\n",
    "                       [  0. , 137. ,  40. ,  35. , 168. ,  43.1,   2.3,  33. ],\n",
    "                       [  5. , 116. ,  74. ,   0. ,   0. ,  25.6,   0.2,  30. ]])\n",
    "some_labels = np.array([0, 1, 0, 1, 0])\n",
    "\n",
    "some_mu_y = cc_mean_ignore_missing(some_feats, some_labels)\n",
    "\n",
    "assert np.array_equal(some_mu_y.round(2), np.array([[  2.33,   4.  ],\n",
    "                                                    [ 96.67, 160.  ],\n",
    "                                                    [ 68.67,  52.  ],\n",
    "                                                    [ 17.33,  17.5 ],\n",
    "                                                    [ 31.33,  84.  ],\n",
    "                                                    [ 26.77,  33.2 ],\n",
    "                                                    [  0.27,   1.5 ],\n",
    "                                                    [ 27.33,  32.5 ]]))\n",
    "\n",
    "# Checking against the pre-computed test database\n",
    "\n",
    "test_results = test_case_checker(cc_mean_ignore_missing, task_id=2)\n",
    "assert test_results['passed'], test_results['message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "code_folding": [],
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0049c2fb6d47ff8d17a0af12d442a60d",
     "grade": true,
     "grade_id": "cell-e263f2b1878b37bj",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# The following are hints to make your life easier duing debugging if you failed the pre-computed tests.\n",
    "#\n",
    "#   When an error is raised in checking against the pre-computed test database:\n",
    "#\n",
    "#     0. test_results will be a python dictionary, with the bug information stored in it. Don't be afraid to look into it!\n",
    "#\n",
    "#     1. You can access the failed test arguments by reading test_results['test_kwargs']. test_results['test_kwargs'] will be\n",
    "#        another python dictionary with its keys being the argument names and the values being the argument values.\n",
    "#\n",
    "#     2. test_results['correct_sol'] will contain the correct solution.\n",
    "#\n",
    "#     3. test_results['stu_sol'] will contain your implementation's returned solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3.48641975,   4.91866029],\n",
       "       [109.99753086, 142.30143541],\n",
       "       [ 68.77037037,  70.66028708],\n",
       "       [ 19.51358025,  21.97129187],\n",
       "       [ 66.25679012, 100.55980861],\n",
       "       [ 30.31703704,  35.1492823 ],\n",
       "       [  0.42825926,   0.55279904],\n",
       "       [ 31.57283951,  37.39712919]])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu_y = cc_mean_ignore_missing(train_features, train_labels)\n",
    "mu_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\">Task 3</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function `cc_std_ignore_missing` that takes the numpy arrays `train_features` and `train_labels` as input, and outputs the following matrix with the shape $(8,2)$, where 8 is the number of features.\n",
    "\n",
    "$$\\sigma_y = \\begin{bmatrix} \\text{std}[x^{(0)}|y=0] & \\text{std}[x^{(0)}|y=1]\\\\\n",
    "\\text{std}[x^{(1)}|y=0] & \\text{std}[x^{(1)}|y=1] \\\\\n",
    "\\cdots & \\cdots\\\\\n",
    "\\text{std}[x^{(7)}|y=0] & \\text{std}[x^{(7)}|y=1]\\end{bmatrix}$$\n",
    "\n",
    "Some points regarding this task:\n",
    "\n",
    "* The `train_features` numpy array has a shape of `(N,8)` where `N` is the number of training data points, and 8 is the number of the features. \n",
    "\n",
    "* The `train_labels` numpy array has a shape of `(N,)`. \n",
    "\n",
    "* **You can assume that `train_features` has no missing elements in this task**.\n",
    "\n",
    "* Try and avoid the utilization of loops as much as possible. No loops are necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a5ca4c334741188c4e43465b73da4429",
     "grade": false,
     "grade_id": "cell-410ce572204e37df",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def cc_std_ignore_missing(train_features, train_labels):\n",
    "    N, d = train_features.shape\n",
    "    \n",
    "    features_with_labels = np.column_stack((train_features, train_labels)) # matriz de caracteristicas con etiquetas\n",
    "    positive_XY = features_with_labels[features_with_labels[:, -1] == 1, :] # matriz de caracteristicas con etiquetas (positivos)\n",
    "    negative_XY = features_with_labels[features_with_labels[:, -1] == 0, :] # matriz de caracteristicas con etiquetas (negativos)\n",
    "\n",
    "    std_positive = np.std(positive_XY[:, :-1], axis=0) # std de cada característica (positivos)\n",
    "    std_negative = np.std(negative_XY[:, :-1], axis=0) # std de cada característica (negativos)\n",
    "\n",
    "    sigma_y = np.column_stack((std_negative, std_positive))\n",
    "    \n",
    "    return sigma_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "24757c650312d75e519604d242734383",
     "grade": false,
     "grade_id": "cell-347ad2c612aa195e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Performing sanity checks on your implementation\n",
    "\n",
    "some_feats = np.array([[  1. ,  85. ,  66. ,  29. ,   0. ,  26.6,   0.4,  31. ],\n",
    "                       [  8. , 183. ,  64. ,   0. ,   0. ,  23.3,   0.7,  32. ],\n",
    "                       [  1. ,  89. ,  66. ,  23. ,  94. ,  28.1,   0.2,  21. ],\n",
    "                       [  0. , 137. ,  40. ,  35. , 168. ,  43.1,   2.3,  33. ],\n",
    "                       [  5. , 116. ,  74. ,   0. ,   0. ,  25.6,   0.2,  30. ]])\n",
    "some_labels = np.array([0, 1, 0, 1, 0])\n",
    "\n",
    "some_std_y = cc_std_ignore_missing(some_feats, some_labels)\n",
    "\n",
    "assert np.array_equal(some_std_y.round(3), np.array([[ 1.886,  4.   ],\n",
    "                                                     [13.768, 23.   ],\n",
    "                                                     [ 3.771, 12.   ],\n",
    "                                                     [12.499, 17.5  ],\n",
    "                                                     [44.312, 84.   ],\n",
    "                                                     [ 1.027,  9.9  ],\n",
    "                                                     [ 0.094,  0.8  ],\n",
    "                                                     [ 4.497,  0.5  ]]))\n",
    "\n",
    "# Checking against the pre-computed test database\n",
    "\n",
    "test_results = test_case_checker(cc_std_ignore_missing, task_id=3)\n",
    "assert test_results['passed'], test_results['message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "code_folding": [],
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "443f00dc704f8ff5a054e9fa888606f9",
     "grade": true,
     "grade_id": "cell-e263f2b1878b37bg",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# The following are hints to make your life easier duing debugging if you failed the pre-computed tests.\n",
    "#\n",
    "#   When an error is raised in checking against the pre-computed test database:\n",
    "#\n",
    "#     0. test_results will be a python dictionary, with the bug information stored in it. Don't be afraid to look into it!\n",
    "#\n",
    "#     1. You can access the failed test arguments by reading test_results['test_kwargs']. test_results['test_kwargs'] will be\n",
    "#        another python dictionary with its keys being the argument names and the values being the argument values.\n",
    "#\n",
    "#     2. test_results['correct_sol'] will contain the correct solution.\n",
    "#\n",
    "#     3. test_results['stu_sol'] will contain your implementation's returned solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3.1155426 ,   3.75417931],\n",
       "       [ 25.96811899,  32.50910874],\n",
       "       [ 18.07540068,  21.69568568],\n",
       "       [ 15.02320635,  17.21685884],\n",
       "       [ 95.63339586, 139.24364214],\n",
       "       [  7.50030986,   6.6625219 ],\n",
       "       [  0.29438217,   0.37201494],\n",
       "       [ 11.67577435,  11.01543899]])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma_y = cc_std_ignore_missing(train_features, train_labels)\n",
    "sigma_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\">Task 4</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function `log_prob` that takes the numpy arrays `train_features`, $\\mu_y$, $\\sigma_y$, and  $\\log p_y$ as input, and outputs the following matrix with the shape $(N, 2)$\n",
    "\n",
    "$$\\log p_{x,y} = \\begin{bmatrix} \\bigg[\\log p(y=0) + \\sum_{j=0}^{7} \\log p(x_1^{(j)}|y=0) \\bigg] & \\bigg[\\log p(y=1) + \\sum_{j=0}^{7} \\log p(x_1^{(j)}|y=1) \\bigg] \\\\\n",
    "\\bigg[\\log p(y=0) + \\sum_{j=0}^{7} \\log p(x_2^{(j)}|y=0) \\bigg] & \\bigg[\\log p(y=1) + \\sum_{j=0}^{7} \\log p(x_2^{(j)}|y=1) \\bigg] \\\\\n",
    "\\cdots & \\cdots \\\\\n",
    "\\bigg[\\log p(y=0) + \\sum_{j=0}^{7} \\log p(x_N^{(j)}|y=0) \\bigg] & \\bigg[\\log p(y=1) + \\sum_{j=0}^{7} \\log p(x_N^{(j)}|y=1) \\bigg] \\\\\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "where\n",
    "* $N$ is the number of training data points.\n",
    "* $x_i$ is the $i^{th}$ training data point.\n",
    "\n",
    "Try and avoid the utilization of loops as much as possible. No loops are necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hint**: Remember that we are modelling $p(x_i^{(j)}|y)$ with a Gaussian whose parameters are defined inside $\\mu_y$ and $\\sigma_y$. Write the Gaussian PDF expression and take its natural log **on paper**, then implement it.\n",
    "\n",
    "**Important Note**: Do not use third-party and non-standard implementations for computing $\\log p(x_i^{(j)}|y)$. Using functions that find the Gaussian PDF, and then taking their log is **numerically unstable**; the Gaussian PDF values can easily become extremely small numbers that cannot be represented using floating point standards and thus would be stored as zero. Taking the log of a zero value will throw an error. On the other hand, it is unnecessary to compute and store $p(x_i^{(j)}|y)$ in order to find $\\log p(x_i^{(j)}|y)$; you can write $\\log p(x_i^{(j)}|y)$ as a direct function of $\\mu_y$, $\\sigma_y$ and the features. This latter approach is numerically stable, and can be applied when the PDF values are much smaller than could be stored using the common standards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_prob(train_features, mu_y, sigma_y, log_py):\n",
    "    N, d = train_features.shape\n",
    "\n",
    "    log_p_x_y = np.zeros((N, 2)) # crear matriz de la correcta forma para guardar los logaritmos de las probabilidades\n",
    "    for label in [0, 1]:\n",
    "        log_p_x_y[:, label] = np.sum(-0.5 * np.log(2 * np.pi * sigma_y[:, label]**2) \\\n",
    "            - 0.5 * ((train_features - mu_y[:, label])**2) / (sigma_y[:, label]**2),axis=1) + log_py[label]\n",
    "    \n",
    "    assert log_p_x_y.shape == (N, 2)\n",
    "    return log_p_x_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "31f16377027657e8650843f483586a8f",
     "grade": false,
     "grade_id": "cell-86fb4d0c1943d700",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Performing sanity checks on your implementation\n",
    "\n",
    "some_feats = np.array([[  1. ,  85. ,  66. ,  29. ,   0. ,  26.6,   0.4,  31. ],\n",
    "                       [  8. , 183. ,  64. ,   0. ,   0. ,  23.3,   0.7,  32. ],\n",
    "                       [  1. ,  89. ,  66. ,  23. ,  94. ,  28.1,   0.2,  21. ],\n",
    "                       [  0. , 137. ,  40. ,  35. , 168. ,  43.1,   2.3,  33. ],\n",
    "                       [  5. , 116. ,  74. ,   0. ,   0. ,  25.6,   0.2,  30. ]])\n",
    "some_labels = np.array([0, 1, 0, 1, 0])\n",
    "\n",
    "some_mu_y = cc_mean_ignore_missing(some_feats, some_labels)\n",
    "some_std_y = cc_std_ignore_missing(some_feats, some_labels)\n",
    "some_log_py = log_prior(some_labels)\n",
    "\n",
    "some_log_p_x_y = log_prob(some_feats, some_mu_y, some_std_y, some_log_py)\n",
    "\n",
    "assert np.array_equal(some_log_p_x_y.round(3), np.array([[ -20.822,  -36.606],\n",
    "                                                         [ -60.879,  -27.944],\n",
    "                                                         [ -21.774, -295.68 ],\n",
    "                                                         [-417.359,  -27.944],\n",
    "                                                         [ -23.2  ,  -42.6  ]]))\n",
    "\n",
    "# Checking against the pre-computed test database\n",
    "\n",
    "test_results = test_case_checker(log_prob, task_id=4)\n",
    "assert test_results['passed'], test_results['message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "code_folding": [],
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1158d9964f9b5f1d34d7b3d6e19b239b",
     "grade": true,
     "grade_id": "cell-e263f2b1878b37bh",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# The following are hints to make your life easier duing debugging if you failed the pre-computed tests.\n",
    "#\n",
    "#   When an error is raised in checking against the pre-computed test database:\n",
    "#\n",
    "#     0. test_results will be a python dictionary, with the bug information stored in it. Don't be afraid to look into it!\n",
    "#\n",
    "#     1. You can access the failed test arguments by reading test_results['test_kwargs']. test_results['test_kwargs'] will be\n",
    "#        another python dictionary with its keys being the argument names and the values being the argument values.\n",
    "#\n",
    "#     2. test_results['correct_sol'] will contain the correct solution.\n",
    "#\n",
    "#     3. test_results['stu_sol'] will contain your implementation's returned solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-26.96647828, -31.00418408],\n",
       "       [-32.4755447 , -31.39530914],\n",
       "       [-27.14875996, -31.51999532],\n",
       "       ...,\n",
       "       [-26.29368771, -29.09161966],\n",
       "       [-28.19432943, -30.08324788],\n",
       "       [-26.98605248, -30.80571318]])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_p_x_y = log_prob(train_features, mu_y, sigma_y, log_py)\n",
    "log_p_x_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Writing the Simple Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NBClassifier():\n",
    "    def __init__(self, train_features, train_labels):\n",
    "        self.train_features = train_features\n",
    "        self.train_labels = train_labels\n",
    "        self.log_py = log_prior(train_labels)\n",
    "        self.mu_y = self.get_cc_means()\n",
    "        self.sigma_y = self.get_cc_std()\n",
    "        \n",
    "    def get_cc_means(self):\n",
    "        mu_y = cc_mean_ignore_missing(self.train_features, self.train_labels)\n",
    "        return mu_y\n",
    "    \n",
    "    def get_cc_std(self):\n",
    "        sigma_y = cc_std_ignore_missing(self.train_features, self.train_labels)\n",
    "        return sigma_y\n",
    "    \n",
    "    def predict(self, features):\n",
    "        log_p_x_y = log_prob(features, mu_y, sigma_y, log_py)\n",
    "        return log_p_x_y.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_classifier = NBClassifier(train_features, train_labels)\n",
    "train_pred = diabetes_classifier.predict(train_features)\n",
    "eval_pred = diabetes_classifier.predict(eval_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training data accuracy of your trained model is 0.7671009771986971\n",
      "The evaluation data accuracy of your trained model is 0.7532467532467533\n"
     ]
    }
   ],
   "source": [
    "train_acc = (train_pred==train_labels).mean()\n",
    "eval_acc = (eval_pred==eval_labels).mean()\n",
    "print(f'The training data accuracy of your trained model is {train_acc}')\n",
    "print(f'The evaluation data accuracy of your trained model is {eval_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Running an off-the-shelf implementation of Naive-Bayes For Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training data accuracy of your trained model is 0.7671009771986971\n",
      "The evaluation data accuracy of your trained model is 0.7532467532467533\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB().fit(train_features, train_labels)\n",
    "train_pred_sk = gnb.predict(train_features)\n",
    "eval_pred_sk = gnb.predict(eval_features)\n",
    "print(f'The training data accuracy of your trained model is {(train_pred_sk == train_labels).mean()}')\n",
    "print(f'The evaluation data accuracy of your trained model is {(eval_pred_sk == eval_labels).mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 (Building a Naive Bayes Classifier Considering Missing Entries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, we will modify some of the parameter inference functions of the Naive Bayes classifier to make it able to ignore the NaN entries when inferring the Gaussian mean and stds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\">Task 5</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function `cc_mean_consider_missing` that\n",
    "* has exactly the same input and output types as the `cc_mean_ignore_missing` function,\n",
    "* and has similar functionality to `cc_mean_ignore_missing` except that it can handle and ignore the NaN entries when computing the class conditional means.\n",
    "\n",
    "You can borrow most of the code from your `cc_mean_ignore_missing` implementation, but you should make it compatible with the existence of NaN values in the features.\n",
    "\n",
    "Try and avoid the utilization of loops as much as possible. No loops are necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Hint**: You may find the `np.nanmean` function useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d8c4f2e1ed0246c94b6c983bf224f6be",
     "grade": false,
     "grade_id": "cell-6ab8c367d427a588",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def cc_mean_consider_missing(train_features_with_nans, train_labels):\n",
    "    N, d = train_features_with_nans.shape\n",
    "    \n",
    "    mu_y = np.zeros((d, 2))\n",
    "    for label in [0, 1]:\n",
    "        missings = np.ma.masked_invalid(train_features_with_nans[train_labels == label])\n",
    "        mu_y[:, label] = np.ma.mean(missings, axis=0)\n",
    "        mu_y[:, label] = np.ma.filled(mu_y[:, label], np.nan)\n",
    "\n",
    "    assert not np.isnan(mu_y).any()\n",
    "    assert mu_y.shape == (d, 2)\n",
    "    \n",
    "    return mu_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3f4eb8465222ce9813b5a5247743dd40",
     "grade": false,
     "grade_id": "cell-ca4af11e9d8a7fdb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Performing sanity checks on your implementation\n",
    "\n",
    "some_feats = np.array([[  1. ,  85. ,  66. ,  29. ,   0. ,  26.6,   0.4,  31. ],\n",
    "                       [  8. , 183. ,  64. ,   0. ,   0. ,  23.3,   0.7,  32. ],\n",
    "                       [  1. ,  89. ,  66. ,  23. ,  94. ,  28.1,   0.2,  21. ],\n",
    "                       [  0. , 137. ,  40. ,  35. , 168. ,  43.1,   2.3,  33. ],\n",
    "                       [  5. , 116. ,  74. ,   0. ,   0. ,  25.6,   0.2,  30. ]])\n",
    "some_labels = np.array([0, 1, 0, 1, 0])\n",
    "\n",
    "for i,j in [(0,0), (1,1), (2,3), (3,4), (4, 2)]:\n",
    "    some_feats[i,j] = np.nan\n",
    "\n",
    "some_mu_y = cc_mean_consider_missing(some_feats, some_labels)\n",
    "\n",
    "assert np.array_equal(some_mu_y.round(2), np.array([[  3.  ,   4.  ],\n",
    "                                                    [ 96.67, 137.  ],\n",
    "                                                    [ 66.  ,  52.  ],\n",
    "                                                    [ 14.5 ,  17.5 ],\n",
    "                                                    [ 31.33,   0.  ],\n",
    "                                                    [ 26.77,  33.2 ],\n",
    "                                                    [  0.27,   1.5 ],\n",
    "                                                    [ 27.33,  32.5 ]]))\n",
    "\n",
    "# Checking against the pre-computed test database\n",
    "\n",
    "test_results = test_case_checker(cc_mean_consider_missing, task_id=5)\n",
    "assert test_results['passed'], test_results['message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "code_folding": [],
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "668b6db65e5260caafdc68404cb992a3",
     "grade": true,
     "grade_id": "cell-e263f2b1878b37bf",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# The following are hints to make your life easier duing debugging if you failed the pre-computed tests.\n",
    "#\n",
    "#   When an error is raised in checking against the pre-computed test database:\n",
    "#\n",
    "#     0. test_results will be a python dictionary, with the bug information stored in it. Don't be afraid to look into it!\n",
    "#\n",
    "#     1. You can access the failed test arguments by reading test_results['test_kwargs']. test_results['test_kwargs'] will be\n",
    "#        another python dictionary with its keys being the argument names and the values being the argument values.\n",
    "#\n",
    "#     2. test_results['correct_sol'] will contain the correct solution.\n",
    "#\n",
    "#     3. test_results['stu_sol'] will contain your implementation's returned solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3.48641975,   4.91866029],\n",
       "       [109.99753086, 142.30143541],\n",
       "       [ 71.41538462,  75.34693878],\n",
       "       [ 27.53658537,  32.11188811],\n",
       "       [ 66.25679012, 100.55980861],\n",
       "       [ 30.85025126,  35.31826923],\n",
       "       [  0.42825926,   0.55279904],\n",
       "       [ 31.57283951,  37.39712919]])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu_y = cc_mean_consider_missing(train_features_with_nans, train_labels)\n",
    "mu_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\">Task 6</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function `cc_std_consider_missing` that\n",
    "* has exactly the same input and output types as the `cc_std_ignore_missing` function,\n",
    "* and has similar functionality to `cc_std_ignore_missing` except that it can handle and ignore the NaN entries when computing the class conditional means.\n",
    "\n",
    "You can borrow most of the code from your `cc_std_ignore_missing` implementation, but you should make it compatible with the existence of NaN values in the features.\n",
    "\n",
    "Try and avoid the utilization of loops as much as possible. No loops are necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Hint**: You may find the `np.nanstd` function useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fa61452fcd3eebe9fcac747c24973263",
     "grade": false,
     "grade_id": "cell-927753c6215c5646",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def cc_std_consider_missing(train_features_with_nans, train_labels):\n",
    "    N, d = train_features_with_nans.shape\n",
    "    \n",
    "    #get standard deviation\n",
    "    sigma_y = np.zeros((d, 2))\n",
    "    for label in [0, 1]:\n",
    "        missings = np.ma.masked_invalid(train_features_with_nans[train_labels == label])\n",
    "        sigma_y[:, label] = np.ma.std(missings, axis=0)\n",
    "        sigma_y[:, label] = np.ma.filled(sigma_y[:, label], np.nan)\n",
    "    \n",
    "    # Assertion checks\n",
    "    assert not np.isnan(sigma_y).any()\n",
    "    assert sigma_y.shape == (d, 2)\n",
    "    \n",
    "    return sigma_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c870bef906c292c708ad07e06cfaa72f",
     "grade": false,
     "grade_id": "cell-2821b980896856b7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Performing sanity checks on your implementation\n",
    "\n",
    "some_feats = np.array([[  1. ,  85. ,  66. ,  29. ,   0. ,  26.6,   0.4,  31. ],\n",
    "                       [  8. , 183. ,  64. ,   0. ,   0. ,  23.3,   0.7,  32. ],\n",
    "                       [  1. ,  89. ,  66. ,  23. ,  94. ,  28.1,   0.2,  21. ],\n",
    "                       [  0. , 137. ,  40. ,  35. , 168. ,  43.1,   2.3,  33. ],\n",
    "                       [  5. , 116. ,  74. ,   0. ,   0. ,  25.6,   0.2,  30. ]])\n",
    "some_labels = np.array([0, 1, 0, 1, 0])\n",
    "\n",
    "for i,j in [(0,0), (1,1), (2,3), (3,4), (4, 2)]:\n",
    "    some_feats[i,j] = np.nan\n",
    "\n",
    "some_std_y = cc_std_consider_missing(some_feats, some_labels)\n",
    "\n",
    "assert np.array_equal(some_std_y.round(2), np.array([[ 2.  ,  4.  ],\n",
    "                                                     [13.77,  0.  ],\n",
    "                                                     [ 0.  , 12.  ],\n",
    "                                                     [14.5 , 17.5 ],\n",
    "                                                     [44.31,  0.  ],\n",
    "                                                     [ 1.03,  9.9 ],\n",
    "                                                     [ 0.09,  0.8 ],\n",
    "                                                     [ 4.5 ,  0.5 ]]))\n",
    "\n",
    "# Checking against the pre-computed test database\n",
    "\n",
    "test_results = test_case_checker(cc_std_consider_missing, task_id=6)\n",
    "assert test_results['passed'], test_results['message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "code_folding": [],
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "60a17c33bf9e34804095fa6b87f2c1b9",
     "grade": true,
     "grade_id": "cell-e263f2b1878b37bz",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# The following are hints to make your life easier duing debugging if you failed the pre-computed tests.\n",
    "#\n",
    "#   When an error is raised in checking against the pre-computed test database:\n",
    "#\n",
    "#     0. test_results will be a python dictionary, with the bug information stored in it. Don't be afraid to look into it!\n",
    "#\n",
    "#     1. You can access the failed test arguments by reading test_results['test_kwargs']. test_results['test_kwargs'] will be\n",
    "#        another python dictionary with its keys being the argument names and the values being the argument values.\n",
    "#\n",
    "#     2. test_results['correct_sol'] will contain the correct solution.\n",
    "#\n",
    "#     3. test_results['stu_sol'] will contain your implementation's returned solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3.1155426 ,   3.75417931],\n",
       "       [ 25.96811899,  32.50910874],\n",
       "       [ 12.26342359,  12.1982786 ],\n",
       "       [  9.87753687,  10.37284304],\n",
       "       [ 95.63339586, 139.24364214],\n",
       "       [  6.38703834,   6.21564813],\n",
       "       [  0.29438217,   0.37201494],\n",
       "       [ 11.67577435,  11.01543899]])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma_y = cc_std_consider_missing(train_features_with_nans, train_labels)\n",
    "sigma_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Writing the Naive Bayes Classifier With Missing Data Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NBClassifierWithMissing(NBClassifier):\n",
    "    def get_cc_means(self):\n",
    "        mu_y = cc_mean_consider_missing(self.train_features, self.train_labels)\n",
    "        return mu_y\n",
    "    \n",
    "    def get_cc_std(self):\n",
    "        sigma_y = cc_std_consider_missing(self.train_features, self.train_labels)\n",
    "        return sigma_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_classifier_nans = NBClassifierWithMissing(train_features_with_nans, train_labels)\n",
    "train_pred = diabetes_classifier_nans.predict(train_features_with_nans)\n",
    "eval_pred = diabetes_classifier_nans.predict(eval_features_with_nans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training data accuracy of your trained model is 0.7182410423452769\n",
      "The evaluation data accuracy of your trained model is 0.7142857142857143\n"
     ]
    }
   ],
   "source": [
    "train_acc = (train_pred==train_labels).mean()\n",
    "eval_acc = (eval_pred==eval_labels).mean()\n",
    "print(f'The training data accuracy of your trained model is {train_acc}')\n",
    "print(f'The evaluation data accuracy of your trained model is {eval_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Running SVMlight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we are going to investigate the support vector machine classification method. We will become familiar with this classification method in week 3. However, in this section, we are just going to observe how this method performs to set the stage for the third week.\n",
    "\n",
    "`SVMlight` (http://svmlight.joachims.org/) is a famous implementation of the SVM classifier. \n",
    "\n",
    "`SVMLight` can be called from a shell terminal, and there is no nice wrapper for it in python3. Therefore:\n",
    "1. We have to export the training data to a special format called `svmlight/libsvm`. This can be done using scikit-learn.\n",
    "2. We have to run the `svm_learn` program to learn the model and then store it.\n",
    "3. We have to import the model back to python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Exporting the training data to libsvm format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import dump_svmlight_file\n",
    "dump_svmlight_file(train_features, 2*train_labels-1, 'training_feats.data', \n",
    "                   zero_based=False, comment=None, query_id=None, multilabel=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Training `SVMlight`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 8] Exec format error: './svmlight/svm_learn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[153], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchmod +x ./svmlight/svm_learn\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msubprocess\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Popen, PIPE\n\u001b[0;32m----> 3\u001b[0m process \u001b[38;5;241m=\u001b[39m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./svmlight/svm_learn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./training_feats.data\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msvm_model.txt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstdout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPIPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstderr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPIPE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m stdout, stderr \u001b[38;5;241m=\u001b[39m process\u001b[38;5;241m.\u001b[39mcommunicate()\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(stdout\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_env/lib/python3.12/subprocess.py:1026\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize, process_group)\u001b[0m\n\u001b[1;32m   1022\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_mode:\n\u001b[1;32m   1023\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[1;32m   1024\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m-> 1026\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1027\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1028\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1029\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1030\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1031\u001b[0m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1032\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1033\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1034\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocess_group\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1035\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m   1036\u001b[0m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[1;32m   1037\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdin, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr)):\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_env/lib/python3.12/subprocess.py:1950\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session, process_group)\u001b[0m\n\u001b[1;32m   1948\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errno_num \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1949\u001b[0m         err_msg \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mstrerror(errno_num)\n\u001b[0;32m-> 1950\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(errno_num, err_msg, err_filename)\n\u001b[1;32m   1951\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(err_msg)\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 8] Exec format error: './svmlight/svm_learn'"
     ]
    }
   ],
   "source": [
    "!chmod +x ./svmlight/svm_learn\n",
    "from subprocess import Popen, PIPE\n",
    "process = Popen([\"./svmlight/svm_learn\", \"./training_feats.data\", \"svm_model.txt\"], stdout=PIPE, stderr=PIPE)\n",
    "stdout, stderr = process.communicate()\n",
    "print(stdout.decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Importing the SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'svm_model.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[154], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msvm2weight\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_svmlight_weights\n\u001b[0;32m----> 2\u001b[0m svm_weights, thresh \u001b[38;5;241m=\u001b[39m \u001b[43mget_svmlight_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msvm_model.txt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprintOutput\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msvmlight_classifier\u001b[39m(train_features):\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (train_features \u001b[38;5;241m@\u001b[39m svm_weights \u001b[38;5;241m-\u001b[39m thresh)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.\u001b[39m\n",
      "File \u001b[0;32m~/workspace/MachineLearningAlgorithms/BasicClassification/svm2weight.py:20\u001b[0m, in \u001b[0;36mget_svmlight_weights\u001b[0;34m(weights_path, printOutput)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_svmlight_weights\u001b[39m(weights_path, printOutput\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m---> 20\u001b[0m     f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mweights_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m     i\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     22\u001b[0m     lines \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mreadlines()\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'svm_model.txt'"
     ]
    }
   ],
   "source": [
    "from svm2weight import get_svmlight_weights\n",
    "svm_weights, thresh = get_svmlight_weights('svm_model.txt', printOutput=False)\n",
    "\n",
    "def svmlight_classifier(train_features):\n",
    "    return (train_features @ svm_weights - thresh).reshape(-1) >= 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred = svmlight_classifier(train_features)\n",
    "eval_pred = svmlight_classifier(eval_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc = (train_pred==train_labels).mean()\n",
    "eval_acc = (eval_pred==eval_labels).mean()\n",
    "print(f'The training data accuracy of your trained model is {train_acc}')\n",
    "print(f'The evaluation data accuracy of your trained model is {eval_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
